---
title: Deploy a DSL Node
description: An easy guide for deploying an RSS3 Node on the Data Sublayer.
---

![Banner](./assets/deployment-banner.png)

## Introduction

This guide provides instructions for a deployment using containerized solutions including Docker and Kubernetes. It is assumed that the user has a basic understanding of terminal commands and containerization concepts.

The guide is opinionated towards a containerized deployment solution, the source code is available at: https://github.com/RSS3-Network/Node , if one prefers an alternative deployment method.

It's important to note that while the Node itself is production-ready, the deployment methods we outline here may not be universally applicable in all environments. Adaptation of these methods may be necessary to fit the specific requirements of your own setup.

## Deployment

### Prerequisites

- Basic command line proficiency
- Have your [Node registered on the VSL](https://explorer.rss3.io/nodes/register)
- Have docker, docker-compose installed on the server

### Hardware Requirements

Since RSS3 Node's [coverage](/guide/core/dsl/coverage) is highly customizable, there is no universal configuration applicable to all.

You can also choose alternative deployment methods likes:

- [Light Mode](/guide/core/dsl/deployment/light)
- [Serverless](/guide/core/dsl/deployment/serverless)

Our [interactive deployment configurator](https://explorer.rss3.io/nodes/register) will provide an estimated requirement.

We recommend a minimal configuration of 16 Core, 64 GB RAM, 500 GB SSD * 3 to operate a Node with full coverage to boost your work rate. For that, AlloyDB should be used to replace a single PostgreSQL instance, as AlloyDB generally requires fewer resources than a PostgreSQL cluster

### Local AI Capability

Running local AI models requires additional resources (mainly GPUs). It is currently in an internal testing phase, where OpenAgent will be part of the Node to provide AI capabilities.

We will release the relevant documentation soon.

Meanwhile, you can try out [OpenAgent](/guide/core/ai/openagent) on your own server.

### Deploy via docker-compose

A configuration file is required for deploying your Node.

> üëç We strongly recommend that everyone use the [interactive deployment configurator](https://explorer.rss3.io/nodes/register) to minimize the risk of manual errors.

1. During your Node registration [https://explorer.rss3.io/nodes/register](https://explorer.rss3.io/nodes/register), follow the steps and generate a `config.yaml`, and download it.

2. In the same directory as your `config.yaml`, download the automated deployment script by executing the following command:

   ```shell
   curl -s https://raw.githubusercontent.com/RSS3-Network/Node-Automated-Deployer/main/automated_deploy.sh | bash
   ```

üéâ And you are done! (Yes it's that simple.)

### Sample config.yaml

For your reference, a config.yaml should look like this:

```yaml
# DO NOT change this value except for local debugging purposes.
environment: production

# `discovery` is used for Node discovery and verification.
discovery:
  operator:
    evm_address: 0x...address
    signature: 0x...signature
  server:
    endpoint: https://your.node.com
    global_indexer_endpoint: https://gi.rss3.io
    access_token: your_access_token # this will be automatically generated by automated-deployer. Or you can supply your own access token here.

# Database configuration
database:
  driver: postgres
  partition: true
  uri: postgres://postgres:password@localhost:5432/postgres

# A redis is required for monitor service and will significantly improve the indexing performance of some workers.
redis:
  endpoint: localhost:6379
  username:
  password:

# `endpoints` are data access points for Workers.
# Endpoints defined here can be referenced in the configuration below.
# For example,
# - Blockchain networks require RPC endpoints,
# - Arweave requires a gateway endpoint,
# - Farcaster requires a Hubble.
endpoints:
  vsl:
    url: https://rpc.rss3.io
  arweave:
    url: https://arweave.net

# `component` is used to split different types of networks.
component:
  # `rss` network type includes the worker indexing data in RSS format.
  rss:
    id: rss-rsshub
    network: rss
    worker: rsshub
    endpoint: https://your.rsshub.com/
    parameters:
      authentication:
        access_key:
  # `decentralized` network type includes workers indexing data from decentralized networks such as blockchain networks, Arweave, etc.
  decentralized:
    # Each configuration here initializes a worker.
    - id: vsl-core
      network: vsl
      endpoint: vsl
      worker: core
    - id: arweave-mirror
      network: arweave
      endpoint: arweave
      worker: mirror
      ipfs_gateways:
        - https://ipfs.io
        - https://cloudflare-ipfs.com
      parameters:
        concurrent_block_requests: 2
```

### Configuration Options

- `environment`
  - Environment: `NODE_ENVIRONMENT`
  - Default: `development`
  - Description: Environment of the Node, possible values are `development` and `production`.

- `discovery.operator.evm_address`
  - Environment: `NODE_DISCOVERY_OPERATOR_EVM_ADDRESS`
  - Description: Wallet address used during your registration on the RSS3 Explorer.

- `discovery.operator.signature`
  - Environment: `NODE_DISCOVERY_OPERATOR_SIGNATURE`
  - Description:
    - The signature obtained during registration
    - Used to verify your ownership of this Node
    - You MUST NOT share the signature with anyone

- `discovery.server.endpoint`
  - Environment: `NODE_DISCOVERY_SERVER_ENDPOINT`
  - Description:
    - Endpoint is how Global Indexers access your Node
    - You can use a domain or an IP address

- `discovery.server.global_indexer_endpoint`
  - Environment: `NODE_DISCOVERY_SERVER_GLOBAL_INDEXER_ENDPOINT`
  - Default: `https://gi.rss3.io`
  - Description:
    - If your Node is registered on the VSL Testnet, use `https://gi.rss3.dev`
    - Otherwise, DO NOT change this value

- `discovery.server.access_token`
  - Environment: `NODE_DISCOVERY_SERVER_ACCESS_TOKEN`
  - Description:
    - Access token used to gate certain APIs provided by your Node
    - This token is shared with Global Indexers to access your Node
    - This token can be supplied by you or auto-generated by automated deployer

- `database.driver`
  - Environment: `NODE_DATABASE_DRIVER`
  - Default: `postgres`
  - Description: You can use PostgreSQL-compatible database drivers such as `postgres` or `alloydb`

- `database.partition`
  - Environment: `NODE_DATABASE_PARTITION`
  - Default: `true`
  - Description: Whether to use database partitioning

- `database.uri`
  - Environment: `NODE_DATABASE_URI`
  - Default: `postgres://postgres@localhost:5432/postgres`
  - Description: Database connection URI

- `redis.endpoint`
  - Environment: `NODE_REDIS_ENDPOINT`
  - Default: `localhost:6379`
  - Description: Redis server endpoint

- `redis.username`
  - Environment: `NODE_REDIS_USERNAME`
  - Description: Redis username

- `redis.password`
  - Environment: `NODE_REDIS_PASSWORD`
  - Description: Redis password

- `redis.tls.enabled`
  - Environment: `NODE_REDIS_TLS_ENABLED`
  - Default: `false`
  - Description: Whether to enable TLS for Redis connection

- `redis.tls.ca_file`
  - Environment: `NODE_REDIS_TLS_CA_FILE`
  - Description: Path to CA file for Redis TLS

- `redis.tls.cert_file`
  - Environment: `NODE_REDIS_TLS_CERT_FILE`
  - Description: Path to certificate file for Redis TLS

- `redis.tls.key_file`
  - Environment: `NODE_REDIS_TLS_KEY_FILE`
  - Description: Path to key file for Redis TLS

- `redis.tls.insecure_skip_verify`
  - Environment: `NODE_REDIS_TLS_INSECURE_SKIP_VERIFY`
  - Default: `false`
  - Description: Whether to skip TLS verification for Redis

- `stream.enable`
  - Environment: `NODE_STREAM_ENABLE`
  - Default: `false`
  - Description: Whether to enable streaming

- `stream.driver`
  - Environment: `NODE_STREAM_DRIVER`
  - Default: `kafka`
  - Description: Stream driver to use

- `stream.topic`
  - Environment: `NODE_STREAM_TOPIC`
  - Default: `rss3.node.activities`
  - Description: Stream topic

- `stream.uri`
  - Environment: `NODE_STREAM_URI`
  - Default: `localhost:9092`
  - Description: Stream connection URI

- `observability.opentelemetry.metrics.enable`
  - Environment: `NODE_OBSERVABILITY_OPENTELEMETRY_METRICS_ENABLE`
  - Default: `false`
  - Description: Whether to enable OpenTelemetry metrics

- `observability.opentelemetry.metrics.endpoint`
  - Environment: `NODE_OBSERVABILITY_OPENTELEMETRY_METRICS_ENDPOINT`
  - Default: `0.0.0.0:9090`
  - Description: Endpoint for OpenTelemetry metrics

- `observability.opentelemetry.traces.enable`
  - Environment: `NODE_OBSERVABILITY_OPENTELEMETRY_TRACES_ENABLE`
  - Default: `false`
  - Description: Whether to enable OpenTelemetry traces

- `observability.opentelemetry.traces.insecure`
  - Environment: `NODE_OBSERVABILITY_OPENTELEMETRY_TRACES_INSECURE`
  - Default: `false`
  - Description: Whether to use insecure connection for OpenTelemetry traces

- `observability.opentelemetry.traces.endpoint`
  - Environment: `NODE_OBSERVABILITY_OPENTELEMETRY_TRACES_ENDPOINT`
  - Default: `0.0.0.0:4318`
  - Description: Endpoint for OpenTelemetry traces

- `endpoints.*.url`
  - Environment: `NODE_ENDPOINTS_{NAME}_URL`
  - Description: URL for each defined endpoint

- `endpoints.*.http_headers`
  - Environment: `NODE_ENDPOINTS_{NAME}_HTTP_HEADERS`
  - Description: HTTP headers for each defined endpoint

- `endpoints.*.http2_disabled`
  - Environment: `NODE_ENDPOINTS_{NAME}_HTTP2_DISABLED`
  - Default: `false`
  - Description: Whether HTTP/2 is disabled for the endpoint

- `component.rss.id`
  - Environment: `NODE_COMPONENT_RSS_ID`
  - Description: Unique identifier for RSS component

- `component.rss.network`
  - Environment: `NODE_COMPONENT_RSS_NETWORK`
  - Description: Network type for RSS component

- `component.rss.worker`
  - Environment: `NODE_COMPONENT_RSS_WORKER`
  - Description:
    - Actual worker that processes the RSS data
    - You can find the list of available workers here: https://github.com/RSS3-Network/Node/blob/develop/README.md#supported-networks-and-workers

- `component.rss.endpoint`
  - Environment: `NODE_COMPONENT_RSS_ENDPOINT`
  - Description: Endpoint for RSS worker

- `component.rss.parameters`
  - Environment: `NODE_COMPONENT_RSS_PARAMETERS`
  - Description: Additional parameters for RSS component

- `component.decentralized[].id`
  - Description: Unique identifier for each decentralized component

- `component.decentralized[].network`
  - Description: Network type for each decentralized component

- `component.decentralized[].endpoint`
  - Description:
    - Data access endpoint used by the worker
    - You can reference the endpoint defined above in the endpoints section
    - You can also use a direct URL, such as `https://rpc.rss3.io`

- `component.decentralized[].worker`
  - Description:
    - Actual worker that processes the data
    - You can find the list of available workers here: https://github.com/RSS3-Network/Node/blob/develop/README.md#supported-networks-and-workers

- `component.decentralized[].ipfs_gateways`
  - Description:
    - Used to specify the IPFS gateways used by the worker
    - Supplying multiple gateways may improve the indexing performance and reliability

- `component.decentralized[].parameters`
  - Description: Additional parameters for each decentralized component
    - For Ethereum and Arweave:
      - `BlockStart`: Block number/height that the worker should start from
      - `BlockTarget`: Block number/height that the worker should stop at
      - `ConcurrentBlockRequests`: Number of blocks to request concurrently
    - For EVM-based Worker only:
      - `BlockBatchSize`: Number of blocks to fetch in a single batch.
      - `ReceiptsBatchSize`: Number of receipts to fetch in a single batch.
      - `BlockReceiptsBatchSize`: Number of block receipts to fetch in a single batch.
    - For Farcaster:
      - `APIKey`: API key for Farcaster Hubble.
      - `TimestampStart`: The Farcaster seconds timestamp that the worker should start from.

## Deploy via Kubernetes

### Prerequisites

- Have [kind](https://kind.sigs.k8s.io/docs/user/quick-start/#installation) installed
- Have [Helm](https://helm.sh/) installed

### Create a Kubernetes cluster via kind

Create our Kubernetes cluster with the following command

`kind create cluster --name node`

### Deploy using RSS3's Helm Chart

Since Helm uses a chart file for deployment. We can easily deploy a Node by using the chart files provided.

```shell
helm repo add rss3 https://rss3-network.github.io/helm-charts
helm repo update
```

## Get Help

In case you run into any issues, please reach out to us on [Discord](https://link.rss3.io/discord).

## Conclusion

This guide provides basic instructions for deploying an RSS3 Node in containerized environments. For more advanced configurations, refer to the respective Docker or Kubernetes documentation.

This guide adopts an opinionated stance in favor of containerized deployment. We advocate for this approach due to its benefits in ensuring consistency and scalability, promoting ease of portability across various environments. However, we appreciate the diverse preferences and needs within our community, for those who wish to compile and run the application locally, the source code is available on: [https://github.com/RSS3-Network/Node](https://github.com/RSS3-Network/Node).
